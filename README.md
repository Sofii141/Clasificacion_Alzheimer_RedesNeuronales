# Clasificaci√≥n de Alzheimer a partir de RMNs con Redes Neuronales Convolucionales

![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)![TensorFlow](https://img.shields.io/badge/TensorFlow-2.12%2B-orange.svg)![Scikit-learn](https://img.shields.io/badge/scikit--learn-1.2%2B-blueviolet.svg)![License](https://img.shields.io/badge/License-MIT-green.svg)

Este proyecto implementa un modelo de Deep Learning para clasificar im√°genes de resonancia magn√©tica (RMN) cerebral en cuatro estadios de la enfermedad de Alzheimer. Se sigue la metodolog√≠a **CRISP-DM** y se utiliza una **Red Neuronal Convolucional (CNN)** construida con TensorFlow y Keras para lograr una alta precisi√≥n en la clasificaci√≥n.

El modelo final alcanza una **precisi√≥n del 94.8%** en el conjunto de prueba, demostrando una excepcional capacidad para identificar las caracter√≠sticas visuales asociadas a cada etapa de la enfermedad.

---

## üìã Tabla de Contenidos

*   [1. Descripci√≥n del Problema](#1-descripci√≥n-del-problema)
*   [2. Dataset](#2-dataset)
*   [3. Metodolog√≠a CRISP-DM](#3-metodolog√≠a-crisp-dm)
*   [4. Estructura del Proyecto](#4-estructura-del-proyecto)
*   [5. Instalaci√≥n](#5-instalaci√≥n)
*   [6. Uso](#6-uso)
*   [7. Arquitectura del Modelo](#7-arquitectura-del-modelo)
*   [8. Resultados y Evaluaci√≥n](#8-resultados-y-evaluaci√≥n)
*   [9. Conclusiones](#9-conclusiones)
*   [10. Trabajo Futuro](#10-trabajo-futuro)

---

### 1. Descripci√≥n del Problema

El objetivo principal de este proyecto es desarrollar un sistema de clasificaci√≥n autom√°tica que pueda asistir en el diagn√≥stico temprano y la estadificaci√≥n de la enfermedad de Alzheimer. El modelo debe ser capaz de analizar una RMN cerebral y clasificarla en una de las siguientes cuatro categor√≠as:

*   **Sin Demencia (Non Demented)**
*   **Demencia Muy Leve (Very Mild Demented)**
*   **Demencia Leve (Mild Demented)**
*   **Demencia Moderada (Moderate Demented)**

Un desaf√≠o clave del proyecto es el **severo desbalanceo de clases** en el dataset, lo que requiere estrategias espec√≠ficas para asegurar que el modelo sea sensible a las clases minoritarias, especialmente a las m√°s severas.

### 2. Dataset

Se utiliz√≥ el dataset **"Alzheimer MRI Disease Classification Dataset"** disponible en Kaggle, almacenado en formato Parquet.

‚û°Ô∏è **Fuente:** [https://www.kaggle.com/datasets/borhanitrash/alzheimer-mri-disease-classification-dataset](https://www.kaggle.com/datasets/borhanitrash/alzheimer-mri-disease-classification-dataset)

El dataset contiene 6,400 im√°genes de RMN en escala de grises, pre-divididas en conjuntos de entrenamiento (5,120) y prueba (1,280).

### 3. Metodolog√≠a CRISP-DM

El proyecto est√° estructurado siguiendo las fases de la metodolog√≠a CRISP-DM para asegurar un desarrollo riguroso y ordenado.

*   **Fase 1: Comprensi√≥n del Negocio:** Definici√≥n de objetivos y criterios de √©xito.
*   **Fase 2: Comprensi√≥n de los Datos:** An√°lisis Exploratorio de Datos (AED) para identificar caracter√≠sticas clave, distribuci√≥n de clases y el desbalanceo.
*   **Fase 3: Preparaci√≥n de Datos:** Preprocesamiento de im√°genes (redimensionamiento, normalizaci√≥n), codificaci√≥n de etiquetas y c√°lculo de pesos de clase.
*   **Fase 4: Modelado:** Dise√±o, construcci√≥n y compilaci√≥n de la arquitectura de la Red Neuronal Convolucional (CNN).
*   **Fase 5: Evaluaci√≥n:** Entrenamiento del modelo y evaluaci√≥n exhaustiva utilizando m√©tricas clave.
*   **Fase 6: Despliegue (Fuera del alcance):** Esta fase implicar√≠a la implementaci√≥n del modelo en una aplicaci√≥n real.

### 4. Estructura del Proyecto

```
nombre-del-repositorio/
‚îÇ
‚îú‚îÄ‚îÄ üìÅ preprocessed_data/      # Datos procesados listos para el modelado
‚îÇ   ‚îú‚îÄ‚îÄ class_weights.pkl
‚îÇ   ‚îú‚îÄ‚îÄ label_encoder.pkl
‚îÇ   ‚îú‚îÄ‚îÄ X_test.npy
‚îÇ   ‚îú‚îÄ‚îÄ X_train.npy
‚îÇ   ‚îú‚îÄ‚îÄ X_val.npy
‚îÇ   ‚îú‚îÄ‚îÄ y_test_cat.npy
‚îÇ   ‚îú‚îÄ‚îÄ y_test_encoded.npy
‚îÇ   ‚îú‚îÄ‚îÄ y_train_cat.npy
‚îÇ   ‚îî‚îÄ‚îÄ y_val_cat.npy
‚îÇ
‚îú‚îÄ‚îÄ üìÅ test.parquet/           # Datos originales de prueba
‚îÇ
‚îú‚îÄ‚îÄ üìÅ train.parquet/          # Datos originales de entrenamiento
‚îÇ
‚îú‚îÄ‚îÄ üìú CNN-Fase1-Fase2-Fase3.ipynb  # Notebook para fases 1, 2 y 3 (Comprensi√≥n y Preparaci√≥n)
‚îú‚îÄ‚îÄ üìú CNN-Fase4-Fase5.ipynb       # Notebook para fases 4 y 5 (Modelado y Evaluaci√≥n)
‚îî‚îÄ‚îÄ üìÑ README.md                   # Este archivo
```
*Nota: El archivo `best_model_v2.h5` con los pesos del modelo entrenado se genera en el directorio ra√≠z al ejecutar el segundo notebook.*

### 5. Instalaci√≥n

Para ejecutar este proyecto, se recomienda crear un entorno virtual y luego instalar las dependencias.

```bash
# 1. Clona el repositorio
git clone https://github.com/tu-usuario/nombre-del-repositorio.git
cd nombre-del-repositorio

# 2. Crea y activa un entorno virtual (opcional pero recomendado)
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# 3. Instala las librer√≠as necesarias
pip install tensorflow pandas scikit-learn seaborn matplotlib numpy pyarrow
```

### 6. Uso

Los notebooks Jupyter deben ejecutarse en orden, ya que el segundo depende de los archivos generados por el primero.

1.  **Ejecutar `CNN-Fase1-Fase2-Fase3.ipynb`:** Este notebook cargar√° los datos originales desde las carpetas `parquet`, realizar√° el an√°lisis exploratorio y guardar√° los arrays preprocesados en la carpeta `preprocessed_data/`.
2.  **Ejecutar `CNN-Fase4-Fase5.ipynb`:** Este notebook cargar√° los datos preprocesados, construir√°, entrenar√° y evaluar√° la CNN, guardando el mejor modelo como `best_model_v2.h5` y generando todas las visualizaciones de resultados.

### 7. Arquitectura del Modelo

La CNN est√° dise√±ada con bloques convolucionales progresivos para extraer caracter√≠sticas jer√°rquicas, junto con t√©cnicas de regularizaci√≥n para prevenir el sobreajuste.

| Capa                 | Configuraci√≥n                                 | Prop√≥sito                                      |
| -------------------- | --------------------------------------------- | ---------------------------------------------- |
| `Rescaling`          | `1./255`                                      | Normalizar los p√≠xeles al rango.        |
| `Conv2D` x 2 + `MaxPool` | 32 filtros, (3,3), `relu`                     | Extraer caracter√≠sticas de bajo nivel (bordes).    |
| `Conv2D` x 2 + `MaxPool` | 64 filtros, (3,3), `relu`                     | Extraer caracter√≠sticas de nivel medio (formas). |
| `Conv2D` x 2 + `MaxPool` | 128 filtros, (3,3), `relu`                    | Extraer patrones complejos.                    |
| `Flatten`            | -                                             | Convertir mapas 2D a un vector 1D.             |
| `Dense` + `Dropout`  | 512 neuronas, `relu`, Dropout(0.5)            | Capa de clasificaci√≥n densa con regularizaci√≥n.  |
| `Dense` + `Dropout`  | 256 neuronas, `relu`, Dropout(0.4)            | Refinar la clasificaci√≥n.                      |
| `Dense` (Salida)     | 4 neuronas, `softmax`                         | Producir probabilidades para cada clase.       |
| `BatchNormalization` | (Despu√©s de cada `Conv2D` y `Dense`)            | Estabilizar y acelerar el entrenamiento.       |

### 8. Resultados y Evaluaci√≥n

El modelo final, evaluado en el conjunto de prueba, demostr√≥ un rendimiento excepcional con una **precisi√≥n general del 94.8%**.

#### Matriz de Confusi√≥n Normalizada (% Recall)
Esta matriz es clave, ya que muestra la sensibilidad del modelo para cada clase. El **Recall del 100% para 'Moderate Demented'** es el resultado m√°s significativo, indicando que el modelo no clasific√≥ err√≥neamente ning√∫n caso de la etapa m√°s severa.



#### Capacidad Discriminativa (Curva ROC - AUC)
Los valores de **AUC de 0.99 y 1.00** para todas las clases confirman que el modelo tiene una capacidad casi perfecta para distinguir entre las diferentes etapas de la enfermedad, validando su robustez frente al desbalanceo de clases.



### 9. Conclusiones

1.  **Alto Rendimiento Cl√≠nico:** El modelo no solo es preciso, sino tambi√©n altamente sensible (`Recall`), especialmente para las clases m√°s cr√≠ticas, lo que lo convierte en una herramienta de diagn√≥stico potencialmente fiable.
2.  **Modelo Robusto:** La estrategia de usar pesos de clase manej√≥ eficazmente el desbalanceo, lo que se confirma con las excelentes m√©tricas de F1-score y AUC.
3.  **Entrenamiento Controlado:** El uso de callbacks como `EarlyStopping` y `ModelCheckpoint` fue fundamental para prevenir el sobreajuste y asegurar que el modelo final tuviera la mejor capacidad de generalizaci√≥n.
4.  **Superioridad de la CNN:** La arquitectura convolucional fue esencial para capturar las relaciones espaciales y los patrones sutiles en las RMN.

### 10. Trabajo Futuro

*   **Data Augmentation:** Aplicar t√©cnicas de aumento de datos para incrementar la variabilidad del conjunto de entrenamiento y mejorar a√∫n m√°s la generalizaci√≥n.
*   **Transfer Learning:** Experimentar con arquitecturas pre-entrenadas (como VGG16, ResNet, o EfficientNet).
*   **Explainable AI (XAI):** Implementar t√©cnicas como Grad-CAM para visualizar qu√© regiones de la RMN son m√°s importantes para las predicciones del modelo.
*   **Despliegue:** Desarrollar una aplicaci√≥n web simple (usando Streamlit o Flask) donde se pueda cargar una RMN y recibir una clasificaci√≥n del modelo en tiempo real.
